% chapter2.tex
\chapter{Evaluating Fund Manager Skill: a Mixture Model Approach}
\label{chapter:two}

\section{Introduction}
\label{sec:introduction}

The topic of this paper is evaluating the skill of actively managed equity mutual funds.  There are two questions of primary interest.  First, if we consider the population of mutual funds as a whole, is there any evidence that some funds are more skilled than others?  In particular, are there any funds that we expect to produce returns that more than compensate their expenses?  Second, supposing that such funds exist, can we identify these funds consistently enough to capture the value they provide?  These questions are of obvious importance to investors choosing between actively and passively managed mutual fund investments.

In assessing fund manager skill, a critical issue is differentiating between skill and luck. Standard $p$-values are unsuitable criteria for measuring significance when performing multiple hypothesis tests because many of the tests are expected to reject the null hypothesis by chance.  For example, in the case of actively managed equity mutual funds, the empirical distribution of performance is close to normally distributed, consistent with the hypothesis that all differences in performance arise entirely by luck. Recently, \citet{Barras2010} proposed a method to adjust for the existence of false positives based on a technique introduced by \citet{Storey2002} in the context of biostatistical analyses. My paper an alternative perspective on the results found in \citet{Barras2010}. My primary insight is that their framework suggests an alternative estimation technique that enables a more comprehensive description of the distribution of fund performance. In contrast to \citet{Barras2010}, this method leads to a direct and intuitive classification scheme, which I employ to assess the skill of individual funds.  Additionally, my approach is more flexible in that it permits the possibility that the majority of managers generate returns that fail to justify their expenses. From a practical perspective, the alternative method I propose is preferable because it is much simpler to implement, and fast routines exist in several statistical programming languages.

My first set of results focuses on estimation. In this section, I employ the proposed methodology to describe the distribution of skill (\textit{alpha}) amongst actively managed equity mutual funds. The results demonstrate that the collection of funds under consideration is consistent with a distribution in which more than 80\% of funds generate slightly negative alpha, while minority populations of funds produce substantially positive or negative alpha. I label these minority populations the \textit{Good} and \textit{Poor} performers, respectively. These good and poor performing populations are approximately equivalent in size, but the mean performance of the poor performing population is twice that of the good performing population in absolute value. Unlike \citet{Barras2010}, I find little difference between the distribution of long-run performance and the distribution of performance measured over a shorter time horizon.

In the machine learning jargon, my first set of results concern ``unsupervised learning'': there are no means of \textit{directly} testing the quality of the statistical description. In my second set of results, I examine the performance of a simple investment strategy to assess the quality of the parameter estimates indirectly. The investment strategy picks funds based on the unsupervised learning results, and its success depends on the stability of fund classifications over time. In fact, I find limited evidence to support persistence in fund performance: funds are unlikely to be classified as \textit{Good} in consecutive years. When I analyze the performance of the investment strategy, I find that portfolios of \textit{Good} funds generate positive alphas during my sample period, while portfolios of \textit{Poor} managers generate negative alphas. However, in either case, the performance is similar to that of naive portfolios that invest in the top or bottom deciles of funds. Overall, the primary advantage of the classification system is that it frequently finds \textit{no} positive alpha-generating population.

As a final experiment, I address the validity of the proposed methodology in the context of mutual fund analysis by performing a simulation exercise. The results show that the estimation procedure provides accurate estimates for plausible distributions of fund skill. The simulation also produces an intriguing finding: if we accept the model of \citet{Barras2010}, and assume that their estimates are accurate, then the principal results of my investigation are improbable.

My work relates to \citet{Baks2001}, which highlights the importance of investors' priors regarding the distribution of skill in determining allocations of wealth between actively and passively managed funds. Several papers address the issue of false discovery that complicates the task of formally evaluating the distribution of skill. For example, \citet{Kosowski2006} approaches the problem using a bootstrapping procedure. Their evidence suggests that the empirical distribution of fund performance is unlikely to be observed through luck alone, and therefore skilled funds exist. More recently, \citet{Barras2010} attempted to account for false discoveries using a method introduced by \citet{Storey2002} in the context of biostatistical analyses. Their study finds evidence of skill over short time horizons restricted to an early sub-sample of the data. They also determine that the size and performance of the skilled population have decreased over time.

% SECTION: Model
\section{Evaluating Skill}
\label{sec:model}

My strategy involves two parts.  First, I propose a statistical model of the distribution of fund manager ability.  The model assumes the existence of three distinct subpopulations of managers possessing varying degrees of skill: poor, average, and good managers.  Second, I use an unsupervised learning method---an expectation maximization algorithm---to estimate the statistical model.  Expectation-maximization gives a complete description of the distribution of manager skill and leads to an intuitive classification scheme for evaluating individual funds.

\subsection{Framework for evaluating skill}
The setting is that of an investor trying to evaluate mutual funds by their estimated alphas (relative to some asset pricing model). I assume that fund managers belong to one of three subpopulations of funds that possess different levels of skill: the differences in ability manifest themselves as differences in expected risk-adjusted returns across managers. Our investor observes the alpha generated by each fund, but not the subpopulation to which the fund belongs. Her first goal is to discover the proportion of funds belonging to each subpopulation; her second goal is to predict the unobserved class of each fund. It is possible that she performs well on the first task, yet fails at the second, if the number of funds in a particular subpopulation is small, or if manager performance depends on unobserved, time-varying parameters. From an investment stand point, the first task may be important even if the later proves difficult because optimal asset allocation (from a Bayesian perspective) depends on an investor's prior beliefs about investment opportunities.

% figure: mixture
% \begin{figure}[ht!]
% \small
% \centering
% \captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst, width=\linewidth}
% \caption{Mixture distributions}
% \label{fig:mixture}
% \begin{subfigure}[b]{\textwidth}
% \centering
% \includegraphics[width=0.75\textwidth, height=1.75in]{mixture}
% \end{subfigure}
% %
% \begin{subfigure}[b]{\textwidth}
% \centering
% \includegraphics[width=0.75\textwidth, height=1.75in]{alpha-density}
% \end{subfigure}
% \captionsetup{font=footnotesize, justification=justified, width=0.75\textwidth}
% \caption*{Note: (Top) An example of a mixture model. The solid line represents the observed distribution; dotted lines represent the subpopulations. For the distribution shown, the proportions of the subpopulations shown come from \citet{Barras2010}: 23\% (red), 73\% (black), and 4\% (blue). (Bottom) The solid curve represents a kernel density estimate for the distribution of fund $t$-statistics found in the using the full sample of returns from 1975 to 2015; The dotted curve is the best fitting normal distribution fit to the same data.}
% \end{figure}

% figure: mixture
\begin{figure}[ht!]
\small
\centering
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst, width=\linewidth}
\caption{Mixture-of-normals distribution}
\label{fig:mixture}
\centering
% \includegraphics[width=0.75\textwidth, height=1.75in]{mixture}
\includegraphics[width=\textwidth]{mixture}
\captionsetup{font=footnotesize, justification=justified, width=\textwidth}
\caption*{Note: (Top) An example of a mixture model. The solid line represents the observed distribution; dotted lines represent the subpopulations. For the distribution shown, the proportions of the subpopulations shown come from \citet{Barras2010}: 23\% (red), 73\% (black), and 4\% (blue). (Bottom) The solid curve represents a kernel density estimate for the distribution of fund $t$-statistics found in the using the full sample of returns from 1975 to 2015; The dotted curve is the best fitting normal distribution fit to the same data.}
\end{figure}

The specific model I have in mind is the mixture of normals model depicted in Figure \ref{fig:mixture}. With unconditional probability $\pi_j,$ observation $\alpha_i$ is drawn from population $j$. Observations of alpha from population $j$ have a normal distribution with mean $\mu_j$ and standard deviation $\sigma_j$.  The skill level of each observation (denoted by $z_i$) is unobserved by our investor, and she is, therefore, unable to directly estimate the parameters $\mu_j$, $\sigma_j,$ and $\pi_j$ ($j=1,2,3$).  Referring to Figure \ref{fig:mixture}, she observes the full distribution (the solid line), but she believes that the underlying populations exist and attempts to learn the parameters describing them.

\subsection{Estimation procedure}
\label{sec:em}
I use an expectation-maximization algorithm to estimate the parameters of the model. Expectation-maximization is a numerical method used to obtain maximum-likelihood estimates of parameters in statistical models containing latent variables. For example, medical image reconstruction may involve the identification of unobserved tissue types from an f-MRI scan.  The addition of a latent class variable makes the log-likelihood function impossible to maximize explicitly.  Instead, an expectation-maximization algorithm provides an approximate numerical solution (that does not require the computation of derivatives) by replacing the maximization of likelihood by the maximization of \textit{expected} likelihood, conditional on observed data and an evolving estimate of the underlying parameters.

Expectation-maximization algorithms arise in unsupervised learning tasks.  The central idea is that many types of data contain unobserved classes that are approximately normally distributed.  Expectation-maximization provides a means of identifying classes by assuming their existence and identifying (in a statistical sense) a set of distributions that are most consistent with the observed data.  Below I outline the basic algorithm; the appendix contains additional details.

Suppose that a statistical model of interest contains a set of observed variables $\mathbf{x}$, a set of latent variables $\mathbf{z}$, and a set of underlying parameters $\Theta$, the value of which is unknown and must be estimated.  Expectation-maximization works as follows.  First, I choose an initial (coarse) estimate of the underlying parameters, denoted by $\Theta^{(0)}$.  Second, the conditional expectation of the log-likelihood function $L(\Theta; \mathbf{x}, \mathbf{z})$ is computed, treating $\mathbf{z}$ as a random variable with a density conditional on both $\Theta^{(0)}$ (or $\Theta^{(k)}$ in step $k$) and a set of observations $\mathbf{x}$.  Third, I choose $\Theta^{(1)}$ ($\Theta^{(k+1)}$) by maximizing the conditional expectation in the second step with respect to $\Theta$.  I repeat steps two and three until the estimate of $\Theta$ convergences (whenever $\Theta^{(k)}$ sufficiently close to the maximizer of the joint likelihood function).  The resulting estimate is an approximate maximum likelihood estimate.

The mapping between this general description and the present application is as follows.  First, the observed data $\mathbf{x}$ are mutual fund performances.  Second, the latent variable $\mathbf{z}$ is a sequence of unknown fund abilities.  Third, $\Theta$ consists of the means, standard deviations, and weights assigned to each skill population.
%
\begin{equation} \label{eqn:mixture}
\Theta = \begin{pmatrix} \mu_1 & \mu_2 & \mu_3 \\ \sigma_1 & \sigma_2 & \sigma_3 \\ \rho_1 & \rho_2 & \rho_3 \end{pmatrix}.
\end{equation}
%
The expectation-maximization equations can be written down explicitly for the mixture of normals model. In more general settings, expectation-maximization requires numerical evaluation of expectations (c.f. \citet{Casella2010}). Moreover, the estimation procedure generates point estimates of the conditional probabilities that observation $i$ comes from population $j$:
%
\begin{equation}
\label{eq:posterior}
p_j^i = f_{ y_i | x_i, \Theta}(y_i = j),
\end{equation}
%
for $ i = 1, \dots, n$ and $ j = 1, \dots, J$. The estimates yield a simple classification scheme: each observation is identified with the maximum of the final estimated conditional probabilities evaluated at $\Theta = \hat{\Theta}$.  Alternative classification methods can require that $p_j^i$ exceed a specified threshold $\tau \in [0, 1]$.

Maximum likelihood estimators have useful properties under general conditions. First, maximum likelihood estimates are consistent, so we expect them to be close to the true parameter values given a sufficient sample size. Second, maximum likelihood estimates are asymptotically normal with theoretically known asymptotic covariance matrices. Third, maximum likelihood estimates are asymptotically efficient, meaning that $\Theta_{mle}^*$ minimizes the mean squared error amongst the set of consistent estimators (i.e. they achieve the Cramer-Rao bound).

Unfortunately, these results depend on asymptotic arguments: there is no general advice regarding the accuracy of these approximations for finite samples. Furthermore, the theorems that guarantee these properties rely on strong assumptions regarding the relevant data-generating process and, in the case of approximate maximum likelihood estimates, are sensitive to the choice of initialization.  In the results that follow, I perform a simulation exercise that investigates the finite sample properties of the expectation-maximization estimates.

\subsection{Why the EM algorithm?}
The methodology in \citet{Barras2010} estimates the proportion of funds that are skilled, unskilled, or neutral, from which estimates of the false discovery rate are determined. If we accept that the mixture model suggested by the authors offers a good approximation to the true distribution, then it makes sense for us to try to learn the mean and standard deviation of the individual distributions as well. The expectation-maximization algorithms provide direct estimates of these statistics in addition to estimates of the proportions of the different populations. From these values, it is easy to determine the false discovery rate for a given significance level $\alpha$. As I explain below, this perspective leads to a simple and intuitive classification scheme that can be used to construct portfolios of funds that are expected to consist of \textit{Good}, \textit{Bad}, or \textit{Average} performers.


% SECTION: Data
\section{Data}
\label{sec:chp2_data}

I use the CRSP Survivor-Bias-Free Mutual Fund Database to identify open-end, diversified, actively managed mutual funds in existence between 1975 and 2014.  I exclude funds designated as international, balanced, sector, bond, money market or index funds.  From this collection of funds, I identify those with multiple share classes and aggregate their observations, with combined fund returns calculated as monthly TNA-weighted returns.  I further restrict the sample by only including funds with at least sixty months of observations.  I combine the resulting monthly returns data with Fama/French research returns data obtained via Wharton Research Data Services.

I use the returns data to construct a collection of regression intercept estimates (i.e. alphas) and corresponding $t$-statistics. To generate these values using the four-factor model studied by \citet{Carhart1997}:
%
\begin{equation} \label{eqn:carhart} r_{i, t} = \alpha_{i} + b_{i} \cdot r_{m, t} + s_{i} \cdot r_{smb, t} + h_{i} \cdot r_{hml, t} + m_{i} \cdot r_{mom, t} + \epsilon_{i, t}, \end{equation}
%
where $r_{smb, t}, \ r_{hml, t},$ and $r_{mom, t}$ are the month $t$ excess returns of factor-mimicking portfolios capturing size, value, and momentum premiums.  I use $t$-statistics to measure skill because they account for differences in the precision of estimates and are asymptotically Gaussian.  Computing $t$-statistics requires a choice of standard error computation: I compute standard errors according to \citet{Newey1994}, which adjusts for both heteroskedasticity and correlation across error terms.

Table \ref{tab:summary} describes the returns data as well as the distribution of $t$-statistics.  The data contains $t$-statistic observations from 2,831 funds.  In agreement with prior studies, the mean alpha of an equally weighted portfolio of the funds over the full sample period is negative, and the model $R^2$ is close to 1 (e.g. \citet{Barras2010}, \citet{Carhart1997}).

% table: summary
\begin{table}[ht!]
\small
\centering
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption{Summary fund return statistics}
\begin{tabular}{*{7}{c}}
\toprule
Period & $\hat{\alpha}$ & $\hat{b}_{mkt}$ & $\hat{b}_{smb}$ & $\hat{b}_{hml}$ & $\hat{b}_{umd}$ & $R^2$ \\
\midrule
1975-2015 	& -0.5222 & 0.9906 & 0.2327 & -0.0025 &  0.0204 & 0.9792 \\
			&  (0.4814) & (0.0105) & (0.0312) &  (0.0285) &  (0.0174) & \\
1975-1980 	& -0.5562 & 1.0251 & 0.2623 & -0.0705 &  0.1699 & 0.9833 \\
        	&  (1.1701) & (0.0223) & (0.0470) &  (0.0206) &  (0.0351) & \\
1980-1985 	&  0.5616 & 0.9023 & 0.3392 & -0.1827 &  0.0302 & 0.9845 \\
        	&  (0.7112) & (0.0177) & (0.0304) &  (0.0290) &  (0.0288) & \\
1985-1990 	&  1.1940 & 0.9072 & 0.2749 & -0.2193 &  0.0304 & 0.9953 \\
        	&  (0.5749) & (0.0169) & (0.0197) &  (0.0380) &  (0.0209) & \\
1990-1995 	&  0.1405 & 0.9704 & 0.2660 & -0.0920 &  0.0415 & 0.9929 \\
        	&  (0.4917) & (0.0123) & (0.0141) &  (0.0169) &  (0.0106) & \\
1995-2000 	& -1.4164 & 0.9649 & 0.2824 & -0.0032 &  0.0006 & 0.9891 \\
        	&  (0.8081) & (0.0142) & (0.0205) &  (0.0281) &  (0.0195) & \\
2000-2005 	& -0.8233 & 1.0174 & 0.1925 &  0.1278 &  0.0144 & 0.9786 \\
        	&  (1.3075) & (0.0337) & (0.0232) &  (0.0235) &  (0.0242) & \\
2005-2010 	& -0.2280 & 1.0480 & 0.2161 & -0.0864 &  0.0080 & 0.9894 \\
        	&  (0.7886) & (0.0352) & (0.0350) &  (0.0414) &  (0.0172) & \\
2010-2015 	& -1.8202 & 0.9837 & 0.2389 & -0.0233 & -0.0269 & 0.9928 \\
        	&  (0.6278) & (0.0173) & (0.0136) &  (0.0270) &  (0.0132) & \\
\midrule
Min. & $q_{0.25}$ & $q_{0.50}$ & $q_{0.75}$ & Max. & $\bar{\alpha}$ & $\sigma$ \\
\midrule
-4.2230 & -1.3690 & -0.5542 & 0.2865 & 3.1210 & -0.5509 & 1.2274 \\
\bottomrule
\end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.67\linewidth}
\caption*{Note: The table reports the mean estimated coefficients and standard deviations of the \citet{Carhart1997} four factor model for the years between 1975 and 2015 and for each five-year subperiod within that range. The bottom panel reports sample statistics and quantiels for the distribution of fund $t$-statistics using the full sample period.}
\label{tab:summary}
\end{table}

% SECTION: Results
\section{Results}
\label{sec:results}

I begin by applying the expectation-maximization algorithm to the full data set of mutual fund returns. Next, I investigate the possibility of skill existing only over short time periods. I then analyze the distribution of fund performance over time and check for the existence of persistent skill. Finally, I validate my results through a simulation exercise.

\subsection{Long-run skill}
I start by estimating the parameters using $t$-statistics calculated from the complete time series of returns for each fund in the sample, as described in Section \ref{sec:chp2_data}. Table \ref{tab:main} shows the results. The estimates contain several interesting findings.  First, the proportions of good and poor performers are roughly equal, with each subpopulation making up approximately 8\% of the overall population.  The estimated size of the best performing class is much larger than the corresponding estimate found in \citet{Barras2010} (8\% v. 2.5\%), while the predicted size of the poor performing class is significantly smaller (8\% v 23\%). Second, the estimates show that the population of average performing funds has a negative expected $t$-statistic.  This observation calls in to question the assumption that the ``typical'' funds' performance is benign---investing in these funds is, in fact, detrimental in the long-run.  Lastly, there is a substantial spread between the mean of the worst performing class and the best performing class. While the estimated difference in means refers to $t$-statistics, not returns, but it is still clear that there is a substantial cost to investing in poor performing funds.

\subsection{Short-run skill}
Next, I consider the evidence in support of manager skill over short horizons.  Specifically, for each fund, I divide the time series of returns into five year sub-samples starting in the first year of the overall sample period, 1975.  I consider each sub-sample as an individual fund and estimate its $t$-statistic over each sub-period for which the fund has at least 36 months of observations.  This procedure results in 7,806 $t$-statistic observations.  Table \ref{tab:main} shows the maximum-likelihood estimates for the short-run sample.  Overall the distribution of short-run skill is remarkably similar to the distribution of long-run skill.  The primary difference is that the means of the poor and good performers are slightly more extreme in the short-run than in the long-run.  These results match our intuition that extreme short-run performances are less likely over the long-run.

% table: main
\begin{table}[t]
\small
\centering
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption{Parameter estimates based on the EM algorithm}
\begin{tabular}{*{7}{c}}
\toprule
& \multicolumn{6}{c}{Full Sample: 1975-2015} \\
\midrule
& \multicolumn{3}{c}{Long-Run} & \multicolumn{3}{c}{Short-Run} \\
\cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
& Poor & Average & Good & Poor & Average & Good \\
\midrule
$\mu_j$ & -2.3301 & -0.5496 & 1.0760 & -2.6396 & -0.3740 & 1.6500 \\
& (0.3044) & (0.0708) & (0.1228) & (0.0922) & (0.0368) & (0.2832) \\
$\sigma_j$ & 0.8499 & 1.0475 & 0.8518 & 1.0246 & 1.1995 & 1.1360 \\
& (0.1290) & (0.0317) & (0.0574) & (0.0380) & (0.0194) & (0.1196) \\
$\pi_j$ & 0.0778 & 0.8379 & 0.0844 & 0.0908 & 0.8385 & 0.0707 \\
& (0.0174) & (0.0139) & (0.0245) & (0.0088) & (0.0061) & (0.0104) \\
\midrule
& \multicolumn{6}{c}{Barras et al. Sample: 1975-2007} \\
\midrule
& \multicolumn{3}{c}{Long-Run} & \multicolumn{3}{c}{Short-Run} \\
\cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
& Poor & Average & Good & Poor & Average & Good \\
\midrule
$\mu_j$ & -2.6449 & -0.6036 & 1.2372 & -2.6977 & -0.3877 & 1.9183 \\
& (0.3832) & (0.0728) & (0.2411) & (0.3758) & (0.0605) & (0.5631) \\
$\sigma_j$ & 0.8532 & 1.0510 & 0.8212 & 0.9219 & 1.1526 & 1.0289 \\
& (0.1696) & (0.0445) & (0.0985) & (0.1606) & (0.0588) & (0.2457) \\
$\pi_j$ & 0.0841 & 0.8392 & 0.0767 & 0.0844 & 0.8390 & 0.0766 \\
& (0.0261) & (0.0198) & (0.0196) & (0.0237) & (0.0398) & (0.0268) \\
\bottomrule
\end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.62\linewidth}
\caption*{Note: The table shows the parameter estimates for the distribution of mutual fund $t$-statistics.}
\label{tab:main}
\end{table}

\subsection{The evolution of skill}
Having seen the evidence in favor of a large population of good performers, I turn next to an investigation of how the distribution of fund skill has evolved. To do so, I perform the following experiment: for each year I repeat the long-run estimation procedure using the entire time series of returns up to the beginning of that year, starting with 1990 and ending with 2015. This process results in times series for the parameter estimates $\{\mu_t, \sigma_t, \rho_t\}_{t=1990,\dots,2015}$.

The results are shown in Figure \ref{fig:estimates}. The time series of estimated means do not demonstrate any strong trends over the sample period. On the contrary, the estimates have been remarkably stable, particularly over the last ten years. The time series of estimated weights also display little variation over the last decade.

These results are much different from the time series results in \citet{Barras2010}.  In that paper, the authors find a strong downward trend in the size of the skilled population, as well as a corresponding increase in the population of unskilled funds.  While a reduction in the size of the skilled manager population is consistent with the theoretical predictions found in \citet{Berk2004} and \citet{Pastor2012}, a dramatic increase in the size of the unskilled population requires further explanation.

\subsection{The persistence of skill}
The results thus far demonstrate that fund returns are consistent with the presence of multiple levels of manager ability and that the properties of these classes are stable over time. It is possible, however, that the constituents of the subpopulations are unstable, making it difficult to capitalize on the performance of the best funds. To address this issue, I use a classification scheme to construct portfolios of above and below average performing funds and evaluate their out-of-sample performance.

Starting from January 1, 1980, each year I estimate the skill distribution parameters using the preceding five years of returns. I include all funds that have at least 36 months of observations over this period. Using these estimates, I calculate the conditional probability that each return belongs to the above average population given its estimated $t$-statistic. I then construct five equal-weighted portfolios of good performers based on fixed probability thresholds $\tau = 0.50, 0.60, \dots, 0.90$.  The classification rule is simple: $P(z_i = j; \hat{\Theta}) > \tau \Rightarrow \hat{z}_i = j$.  If no good funds are found at a particular threshold, then the returns over the holding period for that portfolio are the monthly market returns ($\alpha = 0$).  Otherwise, the portfolio is held for one year, after which I repeat the classification procedure.  For comparison, I form corresponding portfolios of poor performing funds, as well as a portfolio of ``average'' funds.

Table \ref{tab:proportions} describes the composition of the resulting portfolios using the proportion of funds assigned to each portfolio.  The proportion of funds in each portfolio is ordinarily smaller than the estimated proportion of funds belonging to the corresponding class due to the threshold criteria.  In fact, in many years no funds are assigned to the portfolios constructed using the highest threshold: 13 (14) out of 35 years I fail to find any good (poor) funds with high probability.

% table: proportions
\begin{table}[t]
\centering
\small
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption{Fund classification proportions}
\begin{tabular}{*{8}{c}}
\toprule
& & &\multicolumn{5}{c}{Proportion} \\
\cmidrule{4-8}
Population & $\tau$ & $\bar{\pi}_c$ & $=0\%$ & $0-6\%$ & $6-12\%$ & $12-24\%$ & $>24\%$ \\
\midrule
Poor & 0.90 & 0.0257 &    13 &    21 &     0 &     0 &     1 \\
Poor & 0.80 & 0.0365 &     6 &    26 &     2 &     0 &     1 \\
Poor & 0.70 & 0.0496 &     2 &    27 &     5 &     0 &     1 \\
Poor & 0.60 & 0.0629 &     0 &    28 &     4 &     2 &     1 \\
Poor & 0.50 & 0.0787 &     0 &    21 &    10 &     2 &     2 \\
Ave. & 0.00 & 0.8381 &     0 &     0 &     0 &     2 &    33 \\
Good & 0.50 & 0.0833 &     0 &    23 &     8 &     2 &     2 \\
Good & 0.60 & 0.0695 &     0 &    27 &     5 &     1 &     2 \\
Good & 0.70 & 0.0585 &     3 &    26 &     3 &     1 &     2 \\
Good & 0.80 & 0.0469 &     8 &    23 &     1 &     1 &     2 \\
Good & 0.90 & 0.0348 &    14 &    18 &     1 &     1 &     1 \\
\bottomrule
\end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.70\linewidth}
\caption*{Note: At the beginning of each formation year every fund with at least 36 months of returns during the preceding 60 months is classified according to its estimated conditional probability of belonging to either the $Bad$, $Neutral$, or $Good$ population of funds.  For each population an equal-weighted portfolio is formed and held for the following 12 months.  This process is repeated at the beginning of each year from 1980 to 2014.  If a fund disappears during a holding period, then it is dropped and its weight reassigned to the remaining funds.  A fund is classified as $Neutral$ if it is not assigned to any of the $Bad$ or $Good$ populations with the probabilities shown. $\hat{\pi}_{pop}$ is the average proportion of funds assigned to the corresponding population.  The remaining values are the number of years for which the estimated proportion of funds in the corresponding population ($\hat{\pi}_t$) falls in the corresponding interval.}
\label{tab:proportions}
\end{table}

% figure: estimates
% \begin{figure}[ht!]
% \small
% \centering
% \captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst, width=\linewidth}
% \caption{Time series of parameter estimates}
% \label{fig:estimates}
% \begin{subfigure}[b]{\textwidth}
% \centering
% \includegraphics[width=0.75\textwidth]{means}
% \end{subfigure}
% %
% \begin{subfigure}[b]{\textwidth}
% \centering
% \includegraphics[width=0.75\textwidth]{weights}
% \end{subfigure}
% \captionsetup{font=footnotesize, justification=justified, width=0.75\textwidth}
% \caption*{Note: (Top) For year from 1980 to 2015 I plot the time series of the estimated populations means of the mixture model for $t$-statistics using fund returns up to that year. (Bottom) The estimated populations weights of the mixture model for $t$-statistics using fund returns up to that year.}
% \end{figure}

% figure: estimates
\begin{figure}[ht!]
\small
\centering
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst, width=\linewidth}
\caption{Time series of parameter estimates}
\label{fig:estimates}
\centering
\includegraphics[width=\textwidth]{time-series}
\captionsetup{font=footnotesize, justification=justified, width=\textwidth}
\caption*{Note: (Top) For year from 1980 to 2015 I plot the time series of the estimated populations means of the mixture model for $t$-statistics using fund returns up to that year. (Bottom) The estimated populations weights of the mixture model for $t$-statistics using fund returns up to that year.}
\end{figure}

Table \ref{tab:turnover} shows the turnover of each portfolio.  For each portfolio, I calculate the probability that a fund assigned to that portfolio is re-assigned to that portfolio in future years.  The results show that there is moderate persistence over short time horizons of up to two years and that the level of persistence decreases as the threshold increases. For example, at the 80\% threshold level, I find that there is a 20\% chance that a fund is re-assigned to either of the good or poor classes one year after being assigned to the same portfolio.  At the 90\% threshold level, the probability drops to less than 10\%.

% table: turnover
\begin{table}[t]
\centering
\small
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption{Fund classification turnover}
    \begin{tabular}{*{7}{c}}
    \toprule
    & & \multicolumn{5}{c}{Years After Classification} \\
    \cmidrule{3-7}
    Population & $\tau$ & 1 & 2 & 3 & 4 & 5 \\
    \midrule
    Poor & 0.90 & 0.0578 & 0.0588 & 0.0441 & 0.0195 & 0.0129 \\
    Poor & 0.80 & 0.1962 & 0.1149 & 0.0595 & 0.0372 & 0.0329 \\
    Poor & 0.70 & 0.2651 & 0.1621 & 0.1005 & 0.0681 & 0.0491 \\
    Poor & 0.60 & 0.3272 & 0.2032 & 0.1292 & 0.0877 & 0.0564 \\
    Poor & 0.50 & 0.3684 & 0.2435 & 0.1538 & 0.1065 & 0.0689 \\
    Ave. & - & 0.8993 & 0.8539 & 0.8136 & 0.7831 & 0.7509 \\
    Good & 0.50 & 0.3428 & 0.1916 & 0.1002 & 0.0754 & 0.0419 \\
    Good & 0.60 & 0.2939 & 0.1613 & 0.0756 & 0.0609 & 0.0352 \\
    Good & 0.70 & 0.2390 & 0.1312 & 0.0526 & 0.0540 & 0.0324 \\
    Good & 0.80 & 0.1930 & 0.1169 & 0.0372 & 0.0525 & 0.0263 \\
    Good & 0.90 & 0.0909 & 0.1010 & 0.0209 & 0.0383 & 0.0105 \\
    \bottomrule
    \end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.58\linewidth}
\caption*{Note: At the beginning of each formation year every fund with at least 36 months of returns during the preceding 60 months is classified according to its estimated conditional probability of belonging to either the $Bad$, $Neutral$, or $Good$ population of funds.  For each population an equal-weighted portfolio is formed and held for the following 12 months.  This process is repeated at the beginning of each year from 1980 to 2014.  If a fund disappears during a holding period, then it is dropped and its weight reassigned to the remaining funds.  A fund is classified as $Neutral$ if it is not assigned to any of the $Bad$ or $Good$ populations with the probabilities shown.  $\hat{\alpha}$ is the intercept from the regression $\tilde{r}_{p,t} = \alpha + \beta^\top f_{t}$.  $p$-values are calculated from $t$-statistics based on homoskedastic standard errors. $\hat{\alpha}$, $\bar{r}$, and $\sigma$ are annualized.}
\label{tab:turnover}
\end{table}

Table \ref{tab:performance} analyzes the performance of each portfolio. I evaluate the performance of portfolios using the same four-factor model used to calculate individual fund $t$-statistics.  The results show that portfolios of the best funds generate positive out-of-sample alphas, although none of these are statistically significant by conventional standards.  Contrary to what one might expect, the alphas are not increasing (decreasing) in $\tau$ for the good (poor) portfolios.  The reasons for this are that the classification is imperfect, and the default passive investment is more likely to be used at higher thresholds. Also, note that the performances of the poor class are highly statistically significant, as is the performance of the average portfolio.  Thus our classification procedure provides a substantial benefit to an investor choosing amongst actively managed funds.

Figure \ref{fig:performance} shows the performance of the good and poor portfolios over time. From the time series of monthly portfolio returns, I construct time series of portfolio alphas by running four-factor regressions at the beginning of each year, starting in January 1990.  The results for the top performers tell a different story from Figure \ref{fig:estimates}: the portfolio alphas decrease steadily, suggesting that either the size or ability of the best performing population declined over this part of the sample.  The disparity may be due to the fact that the earlier results use expanding windows, but it also a reflects the high turnover documented in Table \ref{tab:turnover}.

% table: performance
\begin{sidewaystable}[t]
\centering
\small
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption{Fund performance by classification}
\label{tab:performance}
    \begin{tabular}{*{10}{c}}
    \toprule
    Population & $\tau$ & $\hat{\alpha}$ & $p$ & $\hat{b}_{mkt}$ & $\hat{b}_{smb}$ & $\hat{b}_{hml}$ & $\hat{b}_{umd}$ & $\bar{r}_p$ & $\sigma_p$ \\
    \midrule
    Poor & 0.90 & -2.0042 & 0.0120 & 1.0053 & 0.1036 & 0.0304 & 0.0394 & 6.3884 & 1.6443 \\
    Poor & 0.80 & -2.1981 & 0.0023 & 1.0183 & 0.1566 & 0.0226 & 0.0340 & 6.3103 & 1.6733 \\
    Poor & 0.70 & -2.7453 & 0.0004 & 0.9814 & 0.1321 & 0.0447 & 0.0258 & 5.4578 & 1.6117 \\
    Poor & 0.60 & -3.0279 & 0.0002 & 0.9931 & 0.1464 & 0.0391 & 0.0331 & 5.3219 & 1.6398 \\
    Poor & 0.50 & -2.7651 & 0.0000 & 0.9974 & 0.1571 & 0.0325 & 0.0193 & 5.5094 & 1.6339 \\
    Ave. & - & -1.0887 & 0.0070 & 0.9930 & 0.2128 & -0.0100 & 0.0164 & 7.0635 & 1.6359 \\
    Good & 0.50 & 0.2181 & 0.6689 & 0.9547 & 0.3339 & -0.0444 & 0.0038 & 8.0436 & 1.6549 \\
    Good & 0.60 & 0.5612 & 0.2739 & 0.9428 & 0.3317 & -0.0409 & -0.0102 & 8.1998 & 1.6368 \\
    Good & 0.70 & 0.4212 & 0.4887 & 0.9561 & 0.3317 & -0.0534 & -0.0134 & 8.0944 & 1.6727 \\
    Good & 0.80 & 0.7060 & 0.2833 & 0.9560 & 0.2676 & -0.0276 & -0.0323 & 8.2341 & 1.6435 \\
    Good & 0.90 & 0.5404 & 0.4887 & 0.9534 & 0.2027 & -0.0006 & -0.0299 & 8.0620 & 1.6205 \\
    \bottomrule
    \end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.72\linewidth}
\caption*{Note: At the beginning of each formation year every fund with at least 36 months of returns during the preceding 60 months is classified according to its estimated conditional probability of belonging to either the $Bad$, $Neutral$, or $Good$ population of funds.  For each population an equal-weighted portfolio is formed and held for the following 12 months.  This process is repeated at the beginning of each year from 1980 to 2014.  If a fund disappears during a holding period, then it is dropped and its weight reassigned to the remaining funds.  A fund is classified as $Neutral$ if it is not assigned to any of the $Bad$ or $Good$ populations with the probabilities shown.  The values in this table are estimates of the probability that a fund assigned to a particular population at time $t$ is assigned to the same population at time $t+s$ for $s = 1, \dots, 5$.}
\end{sidewaystable}

Care is required when interpreting the results shown in Figure \ref{fig:performance}.  What the figure shows is that before 1990 the average performance of the best portfolio was excellent.  The fact that the time series is decreasing over the sample period shown indicates that the portfolio alphas over this period are at best unimpressive, and perhaps negative.  When we compare the time series of the classified portfolios with the performance of the naive portfolio, the fact that the alpha of the naive portfolio decreases more indicates that it performs particularly bad over this range. The reason is that naive portfolio does not account for changes in the distribution of skill.  On the other hand, portfolios based on the classification method automatically adjust to such changes and shift from active to passive strategies.

% fig:performance
% \begin{figure}[ht!]
% \small
% \centering
% \captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst, width=\linewidth}
% \caption{Portfolio performance}
% \label{fig:performance}
% \begin{subfigure}[b]{\textwidth}
% \centering
% \includegraphics[width=0.75\textwidth]{good-alphas}
% \end{subfigure}
% %
% \begin{subfigure}[b]{\textwidth}
% \centering
% \includegraphics[width=0.75\textwidth]{poor-alphas}
% \end{subfigure}
% \captionsetup{font=footnotesize, justification=justified, width=0.75\textwidth}
% \caption*{Note: (Top) Time series alpha estimates for the portfolios of good performers. (Bottom) Time series alpha estimates for the portfolios of poor performers.}
% \end{figure}

% fig:performance
\begin{figure}[ht!]
\small
\centering
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst, width=\linewidth}
\caption{Portfolio performance}
\label{fig:performance}
\centering
\includegraphics[width=\textwidth]{alphas}
\captionsetup{font=footnotesize, justification=justified, width=\textwidth}
\caption*{Note: (Top) Time series alpha estimates for the portfolios of good performers. (Bottom) Time series alpha estimates for the portfolios of poor performers.}
\end{figure}

Based on the results in Table \ref{tab:turnover} we know that the composition of portfolios changes frequently and dramatically.  Instead of measuring performance by alpha as in Table \ref{tab:performance}, which assumes that the factor loadings of the portfolios do not vary over time, we can look at errors based on continually evolving measurements of factor loadings.  Specifically, each year after forming portfolios I calculate the factor loadings from a four-factor model, $\mathbf{B}_t$, and compute the monthly alphas for each of the next twelve months using the formula $\alpha_{t+i} = r_{t+i} - \mathbf{B}_t \mathbf{f}_{t+i}$ ($i=1, 2, \dots, 12$).  This procedure results in a time series of monthly alphas. The results of this approach are displayed in Table \ref{tab:performance}.  I find that the average annualized monthly alphas of portfolios of poor and average performers are substantially lower than those of portfolios of good performers and that all portfolios of good performers have positive average alphas.  The results agree with Table \ref{tab:performance}: despite high fund turnover, the average performance of the classified portfolios agrees with their type and the estimates in Table \ref{tab:main}.

% table: alphas
\begin{sidewaystable}[t]
\centering
\small
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption*{Table \ref{tab:performance} (continued)}
    \begin{tabular}{*{9}{c}}
    \toprule
    Population & $\tau$ & $\bar{\alpha}_t$ & $\sigma(\alpha_t)$ & $q_{0.05}$ & $q_{0.10}$ & $q_{0.50}$ & $q_{0.90}$ & $q_{0.95}$ \\
    \midrule
    Poor & 0.90 & -1.8976 & 0.3782 & -22.4486 & -14.6903 & 0.0000 & 9.0749 & 14.9710 \\
    Poor & 0.80 & -2.8341 & 0.3631 & -20.0108 & -14.8880 & -0.7921 & 7.7922 & 13.0952 \\
    Poor & 0.70 & -3.8121 & 0.4241 & -28.1429 & -17.5550 & -2.4551 & 8.1537 & 14.4757 \\
    Poor & 0.60 & -4.1412 & 0.4389 & -29.5569 & -19.9815 & -3.2508 & 8.7368 & 15.8375 \\
    Poor & 0.50 & -3.4729 & 0.3715 & -23.9097 & -16.3740 & -2.3868 & 8.7435 & 15.0773 \\
    Ave. & - & -1.0487 & 0.2534 & -13.0754 & -10.1157 & -1.3581 & 7.9048 & 11.2645 \\
    Good & 0.50 & 0.2762 & 0.3364 & -15.5591 & -11.4703 & 0.4807 & 11.1805 & 16.2520 \\
    Good & 0.60 & 0.4129 & 0.3394 & -15.5113 & -11.6139 & 0.7028 & 11.8096 & 17.4997 \\
    Good & 0.70 & 0.5706 & 0.3813 & -16.9521 & -12.6671 & 0.0000 & 13.9007 & 17.7370 \\
    Good & 0.80 & 0.5232 & 0.3369 & -14.6665 & -11.6031 & 0.0000 & 12.6060 & 17.7770 \\
    Good & 0.90 & 0.7665 & 0.3500 & -17.4433 & -12.0193 & 0.0000 & 13.9968 & 20.7268 \\
    \bottomrule
    \end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.69\linewidth}
\caption*{Note: At the beginning of each formation year every fund with at least 36 months of returns during the preceding 60 months is classified according to its estimated conditional probability of belonging to either the $Bad$, $Neutral$, or $Good$ population of funds.  For each population an equal-weighted portfolio is formed and held for the following 12 months.  This process is repeated at the beginning of each year from 1980 to 2014.  If a fund disappears during a holding period, then it is dropped and its weight reassigned to the remaining funds.  A fund is classified as $Neutral$ if it is not assigned to any of the $Bad$ or $Good$ populations with the probabilities shown.  Monthly portfolio alphas ($\alpha_t$) are calculated as $r_t - \hat{\beta}_t^\top \mathbf{f}_t$, where $\hat{\beta}_t^\top$ is estimated from the 60 months of returns preceding the formation date.  $\bar{\alpha}_t$ and $\sigma(\alpha_t)$ are the time series mean and standard deviation of $\alpha_t$.  All values are annualized.}
\label{tab:alphas}
\end{sidewaystable}

\subsection{Estimate validation}
\label{sec:simulation}
Expectation-maximization produces numerical approximations to maximum likelihood estimates. Theoretically, maximum likelihood estimates have desirable asymptotic properties: most importantly, they unbiased and efficient.  However, the expectation-maximization algorithm might struggle to learn the parameters of a mixture of normals model if some of the weights are particularly small, or if the densities of the individual distributions have a large amount of overlap (i.e. if the means of the distributions are close relative to their standard deviations). In either case, the algorithm is more likely to converge to a local maximizer. To validate the estimation procedure, I perform a simple experiment in which I estimate the parameters of mixture of normal distributions using simulated data.

For a fixed set of parameters, I generate 1000 samples containing 3000 pseudo-random observations each. Using the same expectation-maximization algorithm applied above, I estimate the parameters of each sample. I then investigate the finite sample distribution of the resulting 1000 estimates.

Table \ref{tab:simulation} shows the results. I compare two choices of parameters, one based on inferred values from \citet{Barras2010}, and the other based on my estimates. Most of the parameters are unbiased: the exceptions are the mean and weight of the good performers under the distribution based on \citet{Barras2010}.  In this case, the population of good funds is simply too small to identify---in fact, the proportion estimated by the authors is not statistically different from zero.

These results present a dilemma: If the mixture of normals model is correct, then the estimated weights should be similar to those found in \citet{Barras2010}. In Table \ref{tab:main}, Panel B I show that using the same sample period as in that paper, this is not the case.  A possible explanation for the discrepancy is that the estimation procedures are sensitive to the treatment of the average population's mean.  We may find more similar results if we restrict the mean of this class to zero.

% table: simulation
\begin{table}[t]
\centering
\small
\captionsetup{labelsep=colon, font=footnotesize, justification=centerfirst}
\caption{Monte Carlo simulation}
\begin{tabular}{*{7}{c}}
    \toprule
    & \multicolumn{6}{c}{\textbf{Panel A: \citet{Barras2010}}} \\
    \midrule
    & \multicolumn{3}{c}{Estimate} & \multicolumn{3}{c}{Bias} \\
    \cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
    & Poor & Average & Good & Poor & Average & Good \\
    \midrule
    $\mu_j$ & -2.5109 & -0.0213 & 2.2712 & -0.0109 & -0.0213 & -0.7288 \\
    $\sigma_j$ & 0.9873 & 0.9877 & 1.2333 & -0.0127 & -0.0123 & 0.2333 \\
    $\pi_j$ & 0.2293 & 0.7332 & 0.0375 & -0.0007 & -0.0168 & 0.0175 \\
    \midrule
    & \multicolumn{6}{c}{\textbf{Panel B: Expectation-Maximization}} \\
    \midrule
    & \multicolumn{3}{c}{Estimate} & \multicolumn{3}{c}{Bias} \\
    \cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
    & Poor & Average & Good & Poor & Average & Good \\
    \midrule
    $\mu_j$ & -2.3764 & -0.5435 & 1.1492 & -0.0264 & 0.0065 & 0.0692 \\
    $\sigma_j$ & 0.8185 & 1.0346 & 0.7995 & -0.0315 & -0.0154 & -0.0505 \\
    $\pi_j$ & 0.0844 & 0.8363 & 0.0793 & 0.0044 & -0.0037 & -0.0007 \\
    \bottomrule
    \end{tabular}
\captionsetup{position=below, font=footnotesize, justification=justified, width=0.57\linewidth}
\caption*{Note: The reported estimates are the mean of 1000 estimates of the mixture of normal distribution parameters.  Each estimate is based on 3000 pseudo-random observations.}
\label{tab:simulation}
\end{table}

% SECTION: Conclusion
\section{Conclusion}
\label{sec:conclusion}
In this paper, I investigated the distribution of skill in the actively-managed equity mutual fund industry. My analysis is based on a simple framework for which precise estimation methods are available. I demonstrate how to apply this structure to evaluate skill in the industry as a whole, and also perform fund-level evaluations. My results show that over an extended sample period the distribution of skill is consistent with the existence of substantial populations of both poor and good performing funds, as well as a majority population of managers that under-performs low-cost, passive investment alternatives. I find mixed results concerning the evolution of the distribution of skill. My formal estimates indicate that this distribution has remained stable over time, but the performance of an investment strategy based on these estimates suggests a decline in either the skill or proportion of skilled funds in the distribution over the latter half of our sample period. I validate these results using a simple simulation exercise.

What are we to conclude of the active management industry? On the one hand, it appears that there is a small number alpha generating managers to be found in the distribution of funds at any particular time. At the same time, predicting which funds will perform well in the future is difficult because the size of the talented pool is small, and its expected excess return is not much larger than that of the average fund. For an investor in this asset class, the easier task is avoiding under-performing funds.
